import numpy as np
import os
from pathlib import Path
from typing import Union, Callable, Any, Literal
from pathos.multiprocessing import ProcessingPool as Pool
import scipy.ndimage
from scipy.spatial.transform import Rotation
from copy import deepcopy
from functools import wraps
import scipy
import json
import pickle
from collections import OrderedDict

from av2.structures.cuboid import Cuboid, CuboidList
from av2.map.map_api import ArgoverseStaticMap
from av2.map.lane_segment import LaneSegment
from av2.map.pedestrian_crossing import PedestrianCrossing
from av2.geometry.se3 import SE3
from av2.utils.io import read_feather, read_city_SE3_ego
from av2.evaluation.tracking.utils import save, load
from av2.datasets.sensor.splits import TEST, TRAIN, VAL
import refAV.paths as paths


class CacheManager:
    def __init__(self):
        self.caches = {}
        self.stats = {}
        self.num_processes = max(int(0.9 * os.cpu_count()), 1)
        self.semantic_lane_cache = None
        self.road_side_cache = None

    def set_num_processes(self, num):
        self.num_processes = max(min(os.cpu_count() - 1, num), 1)

    def make_hashable(self, obj):
        if isinstance(obj, (list, tuple, set)):
            return tuple(self.make_hashable(x) for x in obj)
        elif isinstance(obj, dict):
            return tuple(sorted((k, self.make_hashable(v)) for k, v in obj.items()))
        elif isinstance(obj, Path):
            return str(obj)
        elif isinstance(obj, np.ndarray):
            return tuple(obj.flatten())
        elif isinstance(obj, ArgoverseStaticMap):
            return obj.log_id
        elif isinstance(obj, LaneSegment):
            return obj.id
        elif isinstance(obj, Cuboid):
            return obj.track_uuid
        else:
            return obj

    def create_cache(self, name, maxsize=512):
        if name not in self.caches:
            self.caches[name] = OrderedDict()
            self.stats[name] = {'hits': 0, 'misses': 0}
        
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                key = (
                    self.make_hashable(args),
                    self.make_hashable(kwargs)
                )
                
                cache:OrderedDict = self.caches[name]
                
                if key in cache:
                    cache.move_to_end(key)
                    self.stats[name]['hits'] += 1
                    return cache[key]
                
                result = func(*args, **kwargs)
                self.stats[name]['misses'] += 1

                cache[key] = result
                if len(cache) > maxsize:
                    cache.popitem(last=False)
                    
                return result
            
            wrapper.clear_cache = lambda: self.caches[name].clear()
            wrapper.cache_info = lambda: {
                'name': name,
                'current_size': len(self.caches[name]),
                'maxsize': maxsize
            }
            
            return wrapper
        return decorator
    
    def clear_all(self):
        for cache in self.caches.values():
            cache.clear()
    
    def info(self):
        return {name: len(cache) for name, cache in self.caches.items()}
    
    def get_stats(self, name=None):
        if name:
            stats = self.stats[name]
            total = stats['hits'] + stats['misses']
            hit_rate = stats['hits'] / total if total > 0 else 0
            return {
                'name': name,
                'hits': stats['hits'],
                'misses': stats['misses'],
                'hit_rate': f"{hit_rate:.2%}",
                'cache_size': len(self.caches[name])
            }
        return {
            name: self.get_stats(name) for name in self.stats
        }

    def load_custom_caches(self):

        with open(paths.CACHE_PATH /'semantic_lane_cache.json', 'rb') as file:
            self.semantic_lane_cache = json.load(file)

        with open(paths.CACHE_PATH / 'road_side_cache.json', 'rb') as file:
            self.road_side_cache = json.load(file)
        
cache_manager = CacheManager()

def composable(composable_func):
    """
    A decorator to evaluate track crossings in parallel for the given composable function.
    
    Args:
        composable_func (function): A function that is evaluated on the track and candidate data.
    
    Returns:
        function: A new function that wraps `composable_func` and adds parallel evaluation.
    """
    @wraps(composable_func)
    def wrapper(track_candidates, log_dir, *args, **kwargs):
        """
        The wrapper function that adds parallel processing and filtering to the decorated function.
        
        Args:
            tracks (dict): Keys are track UUIDs, values are lists of valid timestamps.
            candidates (dict): Keys are candidate UUIDs, values are lists of valid timestamps.
            log_dir (Path): Directory containing log data.
            *args, **kwargs: Additional arguments passed to `composable_func`.
            
        Returns:
            dict: Subset of `track_dict` containing tracks being crossed and their crossing timestamps.
            dict: Nested dict where keys are track UUIDs, values are dicts of candidate UUIDs with their crossing timestamps.
        """
        # Process tracks and candidates into dictionaries
        track_dict = to_scenario_dict(track_candidates, log_dir)

        # Parallelize processing of the UUIDs
        all_uuids = list(track_dict.keys())

        true_tracks, _ = parallelize_uuids(composable_func, all_uuids, log_dir, *args, **kwargs)
        # Apply filtering
        scenario_dict = {}

        for track_uuid, unfiltered_related_objects in track_dict.items():
            if true_tracks.get(track_uuid, None) is not None:
                prior_related_objects = scenario_at_timestamps(unfiltered_related_objects, get_scenario_timestamps(true_tracks[track_uuid]))
                scenario_dict[track_uuid] = prior_related_objects   

        return scenario_dict

    return wrapper

def composable_relational(composable_func):
    """
    A decorator to evaluate track crossings in parallel for the given composable function.
    
    Args:
        composable_func (function): A function that is evaluated on the track and candidate data.
    
    Returns:
        function: A new function that wraps `composable_func` and adds parallel evaluation.
    """
    @wraps(composable_func)
    def wrapper(track_candidates, related_candidates, log_dir, *args, **kwargs):
        """
        The wrapper function that adds parallel processing and filtering to the decorated function.
        
        Args:
            tracks (dict): Keys are track UUIDs, values are lists of valid timestamps.
            candidates (dict): Keys are candidate UUIDs, values are lists of valid timestamps.
            log_dir (Path): Directory containing log data.
            *args, **kwargs: Additional arguments passed to `composable_func`.
            
        Returns:
            dict: Subset of `track_dict` containing tracks being crossed and their crossing timestamps.
            dict: Nested dict where keys are track UUIDs, values are dicts of candidate UUIDs with their crossing timestamps.
        """
        # Process tracks and candidates into dictionaries
        track_dict = to_scenario_dict(track_candidates, log_dir)
        related_candidate_dict = to_scenario_dict(related_candidates, log_dir)
        track_dict, related_candidate_dict = remove_nonintersecting_timestamps(track_dict, related_candidate_dict)

        # Parallelize processing of the UUIDs
        track_uuids = list(track_dict.keys())
        candidate_uuids = list(related_candidate_dict.keys())

        _, relationship_dict = parallelize_uuids(composable_func, track_uuids, candidate_uuids, log_dir, *args, **kwargs)

        # Apply filtering
        scenario_dict = {track_uuid: {} for track_uuid in relationship_dict.keys()}

        for track_uuid, unfiltered_related_objects in track_dict.items():
            if isinstance(unfiltered_related_objects, dict) and track_uuid in relationship_dict:
                prior_related_objects = scenario_at_timestamps(unfiltered_related_objects, get_scenario_timestamps(relationship_dict[track_uuid]))
                scenario_dict[track_uuid] = prior_related_objects   

        for track_uuid, unfiltered_related_objects in relationship_dict.items():
            for related_uuid, related_timestamps in unfiltered_related_objects.items():
                eligible_timestamps = sorted(set(related_timestamps).intersection(get_scenario_timestamps(track_dict[track_uuid])))
                scenario_dict[track_uuid][related_uuid] = scenario_at_timestamps(related_candidate_dict[related_uuid], eligible_timestamps)            

        return scenario_dict

    return wrapper


def scenario_at_timestamps(scenario_dict:dict, kept_timestamps):
    scenario_with_timestamps = deepcopy(scenario_dict)

    if not isinstance(scenario_dict, dict):
        return sorted(list(set(scenario_dict).intersection(kept_timestamps)))

    keys_to_remove = []
    for uuid, relationship in scenario_with_timestamps.items():
        relationship = scenario_at_timestamps(relationship, kept_timestamps)
        scenario_with_timestamps[uuid] = relationship
        
        if len(relationship) == 0:
            keys_to_remove.append(uuid)

    for key in keys_to_remove:
        scenario_with_timestamps.pop(key)

    return scenario_with_timestamps


def remove_nonintersecting_timestamps(dict1:dict[str,list], dict2:dict[str,list]):

    dict1_timestamps = get_scenario_timestamps(dict1)
    dict2_timestamps = get_scenario_timestamps(dict2)

    dict1 = scenario_at_timestamps(dict1, dict2_timestamps)
    dict2 = scenario_at_timestamps(dict2, dict1_timestamps)

    return dict1, dict2

@cache_manager.create_cache('get_ego_uuid')
def get_ego_uuid(log_dir):
    df = read_feather(log_dir / 'sm_annotations.feather')
    ego_df = df[df['category'] == 'EGO_VEHICLE']
    return ego_df['track_uuid'].iloc[0]


def get_cuboids_of_category(cuboids: list[Cuboid], category):
    objects_of_category = []
    for cuboid in cuboids:
        if cuboid.category == category:
            objects_of_category.append(cuboid)
    return objects_of_category 


def get_uuids_of_category(log_dir:Path, category:str):
    """
    Returns all uuids from a given category from the log annotations. This method accepts the 
    super classes "ANY" and "VEHICLE".

    Args:
        log_dir: Path to the directory containing scenario logs and data.
        category: the category of objects to return

    Returns: 
        list: the uuids of objects that fall within the category

    Example:
        trucks = get_uuids_of_category(log_dir, category='TRUCK')
    """

    df = read_feather(log_dir / 'sm_annotations.feather')

    if category == 'ANY':
        uuids = df['track_uuid'].unique()
    elif category == 'VEHICLE':

        uuids = []
        vehicle_superclass = ["EGO_VEHICLE","ARTICULATED_BUS","BOX_TRUCK","BUS","LARGE_VEHICLE",
                              "MOTORCYCLE","RAILED_VEHICLE","REGULAR_VEHICLE","SCHOOL_BUS","TRUCK","TRUCK_CAB"]
        
        for vehicle_category in vehicle_superclass:
            category_df = df[df['category'] == vehicle_category]
            uuids.extend(category_df['track_uuid'].unique())
    else:
        category_df = df[df['category'] == category]
        uuids = category_df['track_uuid'].unique()

    return uuids


def has_free_will(track_uuid, log_dir):

    df = read_feather(log_dir / 'sm_annotations.feather')
    category = df[df['track_uuid'] == track_uuid]['category'].iloc[0]
    if category in ['ANIMAL','OFFICIAL_SIGNALER','RAILED_VEHICLE','ARTICULATED_BUS','WHEELED_RIDER','SCHOOL_BUS',
                    'MOTORCYCLIST','TRUCK_CAB','VEHICULAR_TRAILER','BICYCLIST','MOTORCYCLE','TRUCK','BOX_TRUCK','BUS',
                    'LARGE_VEHICLE','PEDESTRIAN','REGULAR_VEHICLE', 'EGO_VEHICLE']:
        return True
    else:
        return False


@composable
def get_object(track_uuid, log_dir):

    df = read_feather(log_dir / 'sm_annotations.feather')
    track_df = df[df['track_uuid'] == track_uuid]

    if track_df.empty:
        print(f'Given track_uuid {track_uuid} not in log annotations.')
        return []
    else:
        timestamps = track_df['timestamp_ns']
        return sorted(timestamps)


@cache_manager.create_cache('get_timestamps')   
def get_timestamps(track_uuid, log_dir):

    df = read_feather(log_dir / 'sm_annotations.feather')
    track_df = df[df['track_uuid'] == track_uuid]

    if track_df.empty:
        print(f'Given track_uuid {track_uuid} not in log annotations.')
        return []
    else:
        timestamps = track_df['timestamp_ns']
        return sorted(timestamps)


@cache_manager.create_cache('get_lane_segments')
def get_lane_segments(avm: ArgoverseStaticMap, position) -> list[LaneSegment]:
    "Get lane segments object is currently in from city coordinate location"
    lane_segments = []

    candidates = avm.get_nearby_lane_segments(position, 5)
    for ls in candidates:
        if is_point_in_polygon(position[:2], ls.polygon_boundary[:,:2]):
            lane_segments.append(ls)

    return lane_segments


@cache_manager.create_cache('get_pedestrian_crossings')
def get_pedestrian_crossings(avm: ArgoverseStaticMap, track_polygon) -> list[PedestrianCrossing]:
    "Get pedestrian crossing that object is currently in from city coordinate location"
    ped_crossings = []

    scenario_crossings = avm.get_scenario_ped_crossings()
    for i, pc in enumerate(scenario_crossings):
        if polygons_overlap(pc.polygon[:,:2], track_polygon[:,:2]):
            ped_crossings.append(pc)

    return ped_crossings


def get_scenario_lanes(track_uuid:str, log_dir:Path, avm=None)->dict[int,LaneSegment]:
    """Returns: scenario_lanes as a dict giving lane the object is in keyed by timestamp"""

    if not avm:
        avm = get_map(log_dir)

    traj, timestamps = get_nth_pos_deriv(track_uuid, 0, log_dir)
    angular_velocities, _ = get_nth_yaw_deriv(track_uuid, 1, log_dir, coordinate_frame='self')

    map_lane_dict = avm.vector_lane_segments
    
    #Key lane segment id, value list of timestamps (associated with trajectory)
    lane_buckets:dict[int, list[int]] = {}

    #Put all points in lane buckets
    #While there exist unassigned points
        #Pop the bucket with the most points
        #Assign timestamps within bucket to popped lane 
        #Remove all points in popped bucket from other buckets

    for i in range(len(timestamps)):

        lane_segments = get_lane_segments(avm, traj[i])

        for ls in lane_segments:
            if ls.id not in lane_buckets:
                lane_buckets[ls.id] = [timestamps[i]]
            else:
                lane_buckets[ls.id].append(timestamps[i])
        
    scenario_lanes:dict[int, LaneSegment] = {}

    while len(lane_buckets) > 0:
        
        most_points = 0
        best_lane_id = None
        for lane_id, lane_timestamps in lane_buckets.items():

            if len(lane_timestamps) > most_points:
                most_points = len(lane_timestamps)
                best_lane_id = lane_id
            elif len(lane_timestamps) == most_points:
                # This often occurs if the objects starts or ends a log
                # at the end or start respectively of an intersection LaneSegment
                ls = map_lane_dict[lane_id]
                turn_direction = get_turn_direction(ls)
                angular_velocity = np.mean(angular_velocities[np.isin(timestamps, lane_timestamps)])

                if (turn_direction == 'left' and angular_velocity > 0.15) \
                or (turn_direction == 'right' and angular_velocity < -0.15) \
                or (turn_direction == 'straight' and 0.15 < angular_velocity < 0.15):
                    most_points = len(lane_timestamps)
                    best_lane_id = lane_id
            
        removed_timestamps = lane_buckets.pop(best_lane_id)
        for timestamp in removed_timestamps:
            scenario_lanes[timestamp] = map_lane_dict[best_lane_id]    

        for lane_id, lane_timestamps in list(lane_buckets.items()):
            remaining_timestamps = list(set(lane_timestamps).difference(removed_timestamps))
            if len(remaining_timestamps) == 0:
                lane_buckets.pop(lane_id)
            else:
                lane_buckets[lane_id] = remaining_timestamps

    for timestamp in timestamps:
        if timestamp not in scenario_lanes:
            scenario_lanes[timestamp] = None

    return scenario_lanes


def get_road_side(ls:LaneSegment, log_dir, side:Literal['same','opposite'], avm=None) -> list[LaneSegment]:

    if not ls:
        return []

    if not avm:
        avm = get_map(log_dir)
    lane_dict = avm.vector_lane_segments
    map_lane_ids = set([ls.id for ls in lane_dict.values()])

    if ls.id not in map_lane_ids:
        return []

    try:
        road_side_cache = cache_manager.road_side_cache
        road_side_ids = road_side_cache[log_dir.name][ls.id][side]
        return [lane_dict[id] for id in road_side_ids]
    except: pass

    same_side_frontier = get_semantic_lane(ls, log_dir, avm=avm)

    same_side = []
    opposite_side = []

    while same_side_frontier:
        lane_segment = same_side_frontier.pop(0)
        same_side.append(lane_segment.id)

        if lane_segment.left_neighbor_id and lane_segment.left_neighbor_id in map_lane_ids:
            left_neighbor = lane_dict[lane_segment.left_neighbor_id]
            left_edge = lane_segment.left_lane_boundary.xyz[:,:2]
            right_edge = left_neighbor.right_lane_boundary.xyz[:,:2]
            edge_distance = np.linalg.norm(left_edge[0]-right_edge[0]) + np.linalg.norm(left_edge[-1]-right_edge[-1])
            if (left_neighbor.id not in opposite_side and left_neighbor.id not in same_side
            and edge_distance < .1):
                same_side_frontier.append(left_neighbor)
            elif left_neighbor.id not in opposite_side and left_neighbor.id not in same_side:
                opposite_side.append(left_neighbor.id)

        if lane_segment.right_neighbor_id and lane_segment.right_neighbor_id in map_lane_ids:
            right_neighbor = lane_dict[lane_segment.right_neighbor_id]
            right_edge = lane_segment.right_lane_boundary.xyz[:,:2]
            left_edge = right_neighbor.left_lane_boundary.xyz[:,:2]
            edge_distance = np.linalg.norm(left_edge[0]-right_edge[0]) + np.linalg.norm(left_edge[-1]-right_edge[-1])

            if (right_neighbor.id not in opposite_side and right_neighbor.id not in same_side
            and edge_distance < .1):
                same_side_frontier.append(right_neighbor)
            elif right_neighbor.id not in opposite_side and right_neighbor.id not in same_side:
                opposite_side.append(right_neighbor.id)

    if side == 'same':
        road_side = [lane_dict[lane_id] for lane_id in same_side]
    elif side == 'opposite':
        if opposite_side:
            road_side = get_road_side(lane_dict[opposite_side[0]], log_dir, side='same')
        else:
            road_side = []
    
    return road_side


def get_semantic_lane(ls: LaneSegment, log_dir, avm=None) -> list[LaneSegment]:
    """Returns a list of lane segments that would make up a single 'lane' coloquailly.
    Finds all lane segments that are directionally forward and backward to the given lane
    segment."""

    if not ls:
        return []

    if not avm:
        avm = get_map(log_dir)
    lane_segments = avm.vector_lane_segments

    try:
        semantic_lanes = cache_manager.semantic_lane_cache[log_dir.name][ls.id]
        all_lanes = avm.vector_lane_segments
        return [all_lanes[ls_id] for ls_id in semantic_lanes]
    except:
        pass

    semantic_lane = [ls]

    if not ls.is_intersection or get_turn_direction(ls) == 'straight':
        predecessors = [ls]
        sucessors = [ls]
    else:
        return semantic_lane

    while predecessors:
        pred_ls = predecessors.pop()
        pred_direction = get_lane_orientation(pred_ls, avm)
        ppred_ids = pred_ls.predecessors
        
        most_likely_pred = None
        best_similarity = 0
        for ppred_id in ppred_ids:
            if ppred_id in lane_segments:
                ppred_ls = lane_segments[ppred_id]
                ppred_direction = get_lane_orientation(ppred_ls, avm)
                similarity = np.dot(ppred_direction, pred_direction)/(np.linalg.norm(ppred_direction)*np.linalg.norm(pred_direction))

                if ((not ppred_ls.is_intersection
                or get_turn_direction(lane_segments[ppred_id]) == 'straight') 
                and similarity > best_similarity):
                    best_similarity = similarity
                    most_likely_pred = ppred_ls

        if most_likely_pred and most_likely_pred not in semantic_lane:
            semantic_lane.append(most_likely_pred)
            predecessors.append(most_likely_pred)

    while sucessors:
        pred_ls = sucessors.pop()
        pred_direction = get_lane_orientation(pred_ls, avm)
        ppred_ids = pred_ls.successors
        
        most_likely_pred = None
        best_similarity = -np.inf
        for ppred_id in ppred_ids:
            if ppred_id in lane_segments:
                ppred_ls = lane_segments[ppred_id]
                ppred_direction = get_lane_orientation(ppred_ls, avm)
                similarity = np.dot(ppred_direction, pred_direction)/(np.linalg.norm(ppred_direction)*np.linalg.norm(pred_direction))

                if ((not ppred_ls.is_intersection
                or get_turn_direction(lane_segments[ppred_id]) == 'straight') 
                and similarity > best_similarity):
                    best_similarity = similarity
                    most_likely_pred = ppred_ls

        if most_likely_pred and most_likely_pred not in semantic_lane:
            semantic_lane.append(most_likely_pred)
            sucessors.append(most_likely_pred)
    
    return semantic_lane


def get_turn_direction(ls: LaneSegment):

    if not ls or not ls.is_intersection:
        return None

    start_direction = ls.right_lane_boundary.xyz[0,:2] - ls.left_lane_boundary.xyz[0,:2]
    end_direction = ls.right_lane_boundary.xyz[-1,:2] - ls.left_lane_boundary.xyz[-1,:2]

    start_angle = np.arctan2(start_direction[0], start_direction[1])
    end_angle = np.arctan2(end_direction[0], end_direction[1])

    angle_change = end_angle - start_angle

    if abs(angle_change) > np.pi:
        if angle_change > 0:
            angle_change -= 2*np.pi
        else:
            angle_change += 2*np.pi

    if angle_change > np.pi/6:
        return 'right'
    elif angle_change < -np.pi/6:
        return 'left'
    else:
        return 'straight'
    

def get_lane_orientation(ls: LaneSegment, avm: ArgoverseStaticMap) -> np.ndarray:
    "Returns orientation (as unit direction vectors) at the start and end of the LaneSegment"
    centerline = avm.get_lane_segment_centerline(ls.id)
    orientation  = centerline[-1] - centerline[0]
    orientation /= np.linalg.norm(orientation + 1e-8)
    return orientation   
        

def unwrap_func(decorated_func: Callable, n=1) -> Callable:
    """Get the original function from a decorated function."""

    unwrapped_func = decorated_func
    for _ in range(n):
        if hasattr(unwrapped_func, '__wrapped__'):
            unwrapped_func = unwrapped_func.__wrapped__
        else:
            break
    
    return unwrapped_func


def parallelize_uuids(
    func: Callable,
    all_uuids: list[str],
    *args,
    **kwargs
) -> tuple[dict[str, Any], dict[str, Any]]:
    """
    Parallelize UUID processing using Pathos ProcessingPool.
    
    Notes:
        - Pathos provides better serialization than standard multiprocessing
        - ProcessingPool.map() is already synchronous and will wait for completion
        - Pathos handles class methods and nested functions better than multiprocessing
    """
    func = unwrap_func(func)

    def worker_func(uuid: str) -> tuple[str, Any, Any]:
        """
        Worker function wrapper that maintains closure over func and its arguments.
        Pathos handles this closure better than standard multiprocessing.
        """
        result = func(uuid, *args, **kwargs)
        if not isinstance(result, tuple):
            result = (result, None)
        timestamps = result[0]
        related = result[1]
        
        return uuid, timestamps, related

    # Initialize the pool
    num_processes = cache_manager.num_processes
    with Pool(nodes=num_processes) as pool:
        # Map work to the pool - this will wait for completion
        results = pool.map(worker_func, all_uuids)
    
    # Process results
    uuid_dict = {}
    related_dict = {}
    
    for uuid, timestamps, related in results: 
        if timestamps is not None:
            uuid_dict[uuid] = timestamps
            related_dict[uuid] = related
    
    return uuid_dict, related_dict
        

def is_point_in_polygon(point, polygon):
    """
    Determine if a point is inside a polygon using the ray-casting algorithm.

    :param point: (x, y) coordinates of the point.
    :param polygon: List of (x, y) coordinates defining the polygon vertices.
    :return: True if the point is inside the polygon, False otherwise.
    """
    x, y = point
    n = len(polygon)
    inside = False

    px1, py1 = polygon[0]
    for i in range(1, n + 1):
        px2, py2 = polygon[i % n]
        if y > min(py1, py2):
            if y <= max(py1, py2):
                if x <= max(px1, px2):
                    if py1 != py2:
                        xinters = (y - py1) * (px2 - px1) / (py2 - py1) + px1
                    if px1 == px2 or x <= xinters:
                        inside = not inside
        px1, py1 = px2, py2

    return inside


@cache_manager.create_cache('polygons_overlap')
def polygons_overlap(poly1, poly2):
    """
    Determine if two polygons overlap using the Separating Axis Theorem (SAT).
    
    Parameters:
    poly1, poly2: Nx2 numpy arrays where each row is a vertex (x,y)
                 First and last vertices should be the same
    visualize: bool, whether to show a visualization of the polygons
    
    Returns:
    bool: True if polygons overlap, False otherwise
    """
    def get_edges(polygon):
        # Get all edges of the polygon as vectors
        return [polygon[i+1] - polygon[i] for i in range(len(polygon)-1)]
    
    def get_normal(edge):
        # Get the normal vector to an edge
        return np.array([-edge[1], edge[0]])
    
    def project_polygon(polygon, axis):
        # Project all vertices onto an axis
        dots = [np.dot(vertex, axis) for vertex in polygon]
        return min(dots), max(dots)
    
    def overlap_on_axis(min1, max1, min2, max2):
        # Check if projections overlap
        return (min1 <= max2 and min2 <= max1) \
                or (min1<=min2 and max1>=max2) \
                or (min2<=min1 and max2>=max1)
    
    # Get all edges from both polygons
    edges1 = get_edges(poly1)
    edges2 = get_edges(poly2)
    
    # Test all normal vectors as potential separating axes
    for edge in edges1 + edges2:
        # Get the normal to the edge
        normal = get_normal(edge)
        
        # Normalize the normal vector
        normal = normal / np.linalg.norm(normal)
        
        # Project both polygons onto the normal
        min1, max1 = project_polygon(poly1, normal)
        min2, max2 = project_polygon(poly2, normal)
        
        # If we find a separating axis, the polygons don't overlap
        if not overlap_on_axis(min1, max1, min2, max2):
            return False
    
    # If we get here, no separating axis was found, so the polygons overlap
    return True


@cache_manager.create_cache('get_nth_pos_deriv')
def get_nth_pos_deriv(
    track_uuid, 
    n, 
    log_dir, 
    coordinate_frame=None,
    direction='forward') -> tuple[np.ndarray, list[int]]:

    """Returns the nth positional derivative of the track at all timestamps 
    with respect to city coordinates. """

    df = read_feather(log_dir / 'sm_annotations.feather')
    ego_poses = get_ego_SE3(log_dir)

    # Filter the DataFrame
    cuboid_df = df[df['track_uuid'] == track_uuid]
    ego_coords = cuboid_df[['tx_m', 'ty_m', 'tz_m']].to_numpy()

    timestamps = cuboid_df['timestamp_ns'].to_numpy()
    city_coords = np.zeros((ego_coords.shape)).T
    for i in range(len(ego_coords)):
        city_coords[:,i] = ego_poses[timestamps[i]].transform_from(ego_coords[i,:])

    city_coords = city_coords.T

    #Very often, different cuboids are not seen by the ego vehicle at the same time.
    #Only the timestamps where both cuboids are observed are calculated.
    if type(coordinate_frame) == str and coordinate_frame != get_ego_uuid(log_dir):
        if coordinate_frame == 'self':
            coordinate_frame = track_uuid

        cf_df = df[df['track_uuid'] == coordinate_frame]
        cf_timestamps = cf_df['timestamp_ns'].to_numpy()

        new_timestamps = np.array(list(set(cf_timestamps).intersection(set(timestamps))))
        new_timestamps.sort(axis=0)

        city_coords = city_coords[np.isin(timestamps, new_timestamps)]
        timestamps = new_timestamps
        cf_df = cf_df[cf_df['timestamp_ns'].isin(timestamps)]
    
    INTERPOLATION_RATE = 1
    prev_deriv = np.copy(city_coords)
    next_deriv = np.zeros(prev_deriv.shape)
    for _ in range(n):
        next_deriv=np.zeros(prev_deriv.shape)
        if len(timestamps) == 1:
            break

        for i in range(len(prev_deriv)):
            past_index = max(0, i-INTERPOLATION_RATE)
            future_index = min(len(timestamps)-1, i+INTERPOLATION_RATE)

            next_deriv[i] = 1e9*(prev_deriv[future_index]-prev_deriv[past_index])/(float(timestamps[future_index]-timestamps[past_index]))

        prev_deriv=np.copy(next_deriv)
    
    if len(timestamps) == 1:
        if n == 0:
            pos_deriv = prev_deriv
        else:
            pos_deriv = np.array([[0,0,0]], dtype=np.float64)
    elif len(timestamps) == 0:
        return prev_deriv, [int(timestamp) for timestamp in timestamps]
    else:
        pos_deriv = scipy.ndimage.median_filter(prev_deriv, size=min(7,len(prev_deriv)), mode='nearest', axes=0) 

    if coordinate_frame == get_ego_uuid(log_dir):
        for i in range(len(pos_deriv)):
            city_to_ego = ego_poses[timestamps[i]].inverse()
            pos_deriv[i] = city_to_ego.transform_from(pos_deriv[i])
            if n != 0:
                #Velocity/acceleration/jerk vectors only need to be rotated
                pos_deriv[i] -= city_to_ego.translation
    elif type(coordinate_frame) == str:

        cf_df = df[df['track_uuid'] == coordinate_frame]
        if cf_df.empty:
            print('Coordinate frame must be None, \'ego\', \'self\', track_uuid, or city to coordinate frame SE3 object.')
            print('Returning answer in city coordinates')
            return pos_deriv, [int(timestamp) for timestamp in timestamps]
        
        cf_df = cf_df[cf_df['timestamp_ns'].isin(timestamps)]
        cf_list = CuboidList.from_dataframe(cf_df)

        for i in range(len(pos_deriv)):
            city_to_ego = ego_poses[timestamps[i]].inverse()  
            ego_to_self = cf_list[i].dst_SE3_object.inverse() 
            city_to_self = ego_to_self.compose(city_to_ego)   
            pos_deriv[i] = city_to_self.transform_from(pos_deriv[i])
            if n != 0:
                #Velocity/acceleration/jerk vectors only need to be rotated
                pos_deriv[i] -= city_to_self.translation
    elif type(coordinate_frame) == SE3:
        pos_deriv = (coordinate_frame.transform_from(pos_deriv.T)).T
    #elif type(coordinate_frame) == list and coordinate_frame and type(coordinate_frame[0]) == SE3 and len(coordinate_frame) == len(prev_deriv):
    elif coordinate_frame is not None:
        print('Coordinate frame must be None, \'ego\', \'self\', track_uuid, or city to coordinate frame SE3 object.')

    if direction == 'left':
        rot_mat = np.array([[0,1,0],[-1,0,0],[0,0,1]])
    elif direction == 'right':
        rot_mat = np.array([[0,-1,0],[1,0,0],[0,0,1]])
    elif direction == 'backward':
        rot_mat = np.array([[-1,0,0],[0,-1,0],[0,0,1]])
    else:
        rot_mat = np.eye(3)

    pos_deriv = (rot_mat @ pos_deriv.T).T

    return pos_deriv, [int(timestamp) for timestamp in timestamps]


def get_nth_radial_deriv(track_uuid, n, log_dir, 
    coordinate_frame=None)->tuple[np.ndarray, np.ndarray]:

    relative_pos, timestamps = get_nth_pos_deriv(track_uuid, 0, log_dir, coordinate_frame=coordinate_frame)
    
    distance = np.linalg.norm(relative_pos, axis=1)
    radial_deriv = distance
    for i in range(n):
        if len(radial_deriv) > 1:
            radial_deriv = np.gradient(radial_deriv)
        else:
            radial_deriv = np.array([0])

    return radial_deriv, timestamps


@cache_manager.create_cache('get_nth_yaw_deriv')
def get_nth_yaw_deriv(track_uuid, n, log_dir, coordinate_frame=None, in_degrees=False):
    """Returns the nth angular derivative of the track at all timestamps 
    with respect to the given coordinate frame. The default coordinate frame is city.
    The returned angle is yaw measured from the x-axis of the track coordinate frame to the x-axis
    of the source coordinate frame"""

    df = read_feather(log_dir / 'sm_annotations.feather')
    ego_poses = get_ego_SE3(log_dir)

    # Filter the DataFrame
    cuboid_df = df[df['track_uuid'] == track_uuid]
    cuboid_list = CuboidList.from_dataframe(cuboid_df)

    self_to_ego_list:list[SE3] = []

    for i in range(len(cuboid_list)):
        self_to_ego_list.append(cuboid_list[i].dst_SE3_object)

    timestamps = cuboid_df['timestamp_ns'].to_numpy()
    self_to_city_list = []
    for i in range(len(self_to_ego_list)):
        self_to_city_list.append(ego_poses[timestamps[i]].compose(self_to_ego_list[i]))

    #Very often, different cuboids are not seen by the ego vehicle at the same time.
    #Only the timestamps where both cuboids are observed are calculated.
    if type(coordinate_frame) == str and coordinate_frame != get_ego_uuid(log_dir):
        if coordinate_frame == 'self':
            coordinate_frame = track_uuid

        cf_df = df[df['track_uuid'] == coordinate_frame]
        cf_timestamps = cf_df['timestamp_ns'].to_numpy()

        if cf_df.empty:
            print('Coordinate frame must be None, \'ego\', \'self\', track_uuid, or city to coordinate frame SE3 object.')
            print('Returning answer in city coordinates')
        else:
            new_timestamps = np.array(list(set(cf_timestamps).intersection(set(timestamps))))
            new_timestamps.sort(axis=0)

            filtered_timestamps = np.isin(timestamps, new_timestamps)

            # Convert mask to indices
            filtered_indices = np.where(filtered_timestamps)[0]

            # Index the list
            filtered_list = [self_to_city_list[i] for i in filtered_indices]
            self_to_city_list = filtered_list
            timestamps = new_timestamps

    city_yaws = np.zeros((len(self_to_city_list),3))
    for i in range(len(self_to_city_list)):
        city_yaws[i] = Rotation.from_matrix(self_to_city_list[i].rotation).as_rotvec()

    INTERPOLATION_RATE = 1
    prev_deriv = np.copy(city_yaws)
    next_deriv = np.zeros(prev_deriv.shape)
    for j in range(n):
        next_deriv=np.zeros(prev_deriv.shape)
        if len(timestamps) == 1:
            break
    
        for i in range(len(prev_deriv)):
            past_index = max(i-INTERPOLATION_RATE,0)
            future_index = min(i+INTERPOLATION_RATE, len(prev_deriv)-1)
            
            difference = prev_deriv[future_index] - prev_deriv[past_index]
            for k in range(len(prev_deriv[0])):
                if j == 0 and abs(difference[k]) > np.pi:
                        if difference[k] > 0:
                            difference[k] -= 2*np.pi
                        else:
                            difference[k] += 2*np.pi

            next_deriv[i] = 1e9*difference/(float(timestamps[future_index]-timestamps[past_index]))

        prev_deriv=np.copy(next_deriv)

    cf_angles = np.copy(prev_deriv)

    if n == 0 and coordinate_frame == get_ego_uuid(log_dir):
        for i in range(len(prev_deriv)):
            city_to_ego = ego_poses[timestamps[i]].inverse().rotation
            cf_angles[i] = Rotation.from_matrix(city_to_ego @ Rotation.from_rotvec(prev_deriv[i]).as_matrix()).as_rotvec()
    elif n == 0 and type(coordinate_frame) == str:
        cf_df = df[df['track_uuid'] == coordinate_frame]
        if not cf_df.empty:
            cf_list = CuboidList.from_dataframe(cf_df)
            for i in range(len(prev_deriv)):
                city_to_ego = ego_poses[timestamps[i]].inverse()
                ego_to_obj = cf_list[i].dst_SE3_object.inverse()
                city_to_obj = ego_to_obj.compose(city_to_ego).rotation
                cf_angles[i] = Rotation.from_matrix(city_to_obj @ Rotation.from_rotvec(prev_deriv[i]).as_matrix()).as_rotvec()
    elif n == 0 and type(coordinate_frame) == SE3:
        for i in range(len(prev_deriv)):
            cf_angles[i] = Rotation.from_matrix(coordinate_frame.rotation @ Rotation.from_rotvec(prev_deriv[i]).as_matrix()).as_rotvec()
    elif n==0 and coordinate_frame is not None:
        print('Coordinate frame must be None, \'ego\', \'self\', track_uuid, or city to coordinate frame SE3 object.')

    if in_degrees: 
        cf_angles = np.rad2deg(cf_angles)

    return cf_angles[:,2], [int(timestamp) for timestamp in timestamps]


def get_log_split(log_dir:Union[str,Path]):
    """Returns the AV2 sensor split for the given log_id or log_dir"""

    log_dir = Path(log_dir)
    if log_dir.stem in VAL:
        split = 'val'
    elif log_dir.stem in TEST:
        split = 'test'
    elif log_dir.stem in TRAIN:
        split = 'train'
    else:
        split = None

    return split


@cache_manager.create_cache('get_map')
def get_map(log_dir: Path):

    log_dir = Path(log_dir)
    try:
        avm = ArgoverseStaticMap.from_map_dir(log_dir / 'map', build_raster=True)
    except:
        split = get_log_split(log_dir)
        avm = ArgoverseStaticMap.from_map_dir(paths.AV2_DATA_DIR / split / log_dir.name / 'map', build_raster=True)
        
    return avm


def get_ego_SE3(log_dir:Path):
    """Returns list of ego_to_city SE3 transformation matrices"""

    log_dir = Path(log_dir)
    try:
        ego_poses = read_city_SE3_ego(log_dir)
    except:
        split = get_log_split(log_dir)
        ego_poses = read_city_SE3_ego(paths.AV2_DATA_DIR / split / log_dir.name)

    return ego_poses


def dilate_convex_polygon(points, distance):
    """
    Dilates the perimeter of a convex polygon specified in clockwise order by a given distance.
    
    Args:
        points (numpy.ndarray): Nx2 array of (x, y) coordinates representing the vertices of the convex polygon
                                in clockwise order. The first and last points are identical.
        distance (float): Distance to dilate the polygon perimeter. Positive for outward, negative for inward.

    Returns:
        numpy.ndarray: Nx2 array of (x, y) coordinates representing the dilated polygon vertices.
                       The first and last points will also be identical.
    """
    def normalize(v):
        """Normalize a vector."""
        norm = np.linalg.norm(v)
        return v / norm if norm != 0 else v

    n = len(points)  # Account for duplicate closing point
    dilated_points = []

    for i in range(1,n):
        # Current, previous, and next points
        prev_point = points[i - 1]  # Previous vertex (wrap around for first vertex)
        curr_point = points[i]     # Current vertex
        next_point = points[(i + 1) % (n-1)]  # Next vertex (wrap around for last vertex)

        # Edge vectors
        edge1 = normalize(curr_point - prev_point)  # Edge vector from prev to curr
        edge2 = normalize(next_point - curr_point)  # Edge vector from curr to next

        # Perpendicular vectors to edges (flipped for clockwise order)
        perp1 = np.array([edge1[1], -edge1[0]])  # Rotate -90 degrees
        perp2 = np.array([edge2[1], -edge2[0]])  # Rotate -90 degrees

        # Average of perpendiculars (to find outward bisector direction)
        bisector = normalize(perp1 + perp2)

        # Avoid division by zero or near-zero cases
        dot_product = np.dot(bisector, perp1)
        if abs(dot_product) < 1e-10:  # Small threshold for numerical stability
            displacement = distance * bisector  # Fallback: scale bisector direction
        else:
            displacement = distance / dot_product * bisector

        # Compute the new vertex
        new_point = curr_point + displacement
        dilated_points.append(new_point)

    # Add the first point to the end to close the polygon
    dilated_points.append(dilated_points[0])
    return np.array(dilated_points)
    

@cache_manager.create_cache('get_cuboid_from_uuid')
def get_cuboid_from_uuid(track_uuid, log_dir, timestamp = None):
    df = read_feather(log_dir / 'sm_annotations.feather')
    
    track_df = df[df["track_uuid"] == track_uuid]

    if timestamp:
        track_df = track_df[track_df["timestamp_ns"] == timestamp]
        if track_df.empty:
            print('Invalid timestamp does not exist for given track_uuid.')
            return None

    track_cuboids = CuboidList.from_dataframe(track_df)
    
    return track_cuboids[0]


@cache_manager.create_cache('to_scenario_dict')
def to_scenario_dict(object_datastructure, log_dir)->dict:

    if isinstance(object_datastructure, dict):
        object_dict = deepcopy(object_datastructure)
    elif isinstance(object_datastructure, list) or isinstance(object_datastructure, np.ndarray):
        object_dict = {uuid: unwrap_func(get_object)(uuid, log_dir) for uuid in object_datastructure}
    elif isinstance(object_datastructure, str):
        object_dict = {object_datastructure: unwrap_func(get_object)(object_datastructure, log_dir)}
    elif isinstance(object_datastructure, int):
        timestamp = object_datastructure
        df = read_feather(log_dir / 'sm_annotations.feather')
        timestamp_df = df[df['timestamp_ns'] == timestamp]

        if timestamp_df.empty:
            print(f'Timestamp {timestamp} not found in annotations')

        object_dict = {track_uuid: [timestamp] for track_uuid in timestamp_df['track_uuid'].unique()}
    else:
        print(f'Provided object, {object_datastructure}, of type {type(object_datastructure)}, must be a track_uuid, list[track_uuid], \
              timestamp, or dict[timestamp:list[timestamp]]')
        print('Comparing to all objects in the log.')

        df = read_feather(log_dir / 'sm_annotations.feather')
        all_uuids = df['track_uuid'].unique()
        object_dict, _ = parallelize_uuids(get_object, all_uuids, log_dir)
    
    return object_dict


@cache_manager.create_cache('cuboid_distance')
def cuboid_distance(cuboid1:Union[str, Cuboid], cuboid2:Union[str, Cuboid], log_dir, timestamp=None) -> float:
    """Returns the minimum distance between two objects at the given timestamp. Timestamp is not required
    if the given objects are single cuboids."""

    if not isinstance(cuboid1, Cuboid):
        cuboid1 = get_cuboid_from_uuid(cuboid1, log_dir, timestamp=timestamp)
    if not isinstance(cuboid2, Cuboid):
        cuboid2 = get_cuboid_from_uuid(cuboid2, log_dir, timestamp=timestamp)

    c1_verts = cuboid1.vertices_m
    c2_verts = cuboid2.vertices_m

    rect1 = np.array([c1_verts[2],c1_verts[6],c1_verts[7],c1_verts[3],c1_verts[2]])[:,:2]
    rect2 = np.array([c2_verts[2],c2_verts[6],c2_verts[7],c2_verts[3],c2_verts[2]])[:,:2]

    distance = min_distance_between_rectangles(rect1, rect2)

    return distance


@cache_manager.create_cache('min_distance_between_rectangles')
def min_distance_between_rectangles(rect1, rect2):
    """ 
    Calculate the minimum distance between two rectangles.
    
    Args:
        rect1: np.array shape (5, 2) - first rectangle (counter-clockwise)
        rect2: np.array shape (5, 2) - second rectangle (counter-clockwise)

    Returns:
        float: Minimum distance between rectangles. Returns 0 if overlapping.
    """
    rect1 = np.asarray(rect1)
    rect2 = np.asarray(rect2)
    
    # Check for overlap
    if polygons_overlap(rect1, rect2):
        return 0.0

    # Check distance from every edge in rect1 to every point in rect2 and vice versa
    min_dist = float('inf')
    for i in range(4):
        a1, a2 = rect1[i], rect1[i+1]
        for j in range(4):
            b1, b2 = rect2[j], rect2[j+1]
            # Point-to-segment distances
            dists = [
                point_to_segment_distance(a1, b1, b2),
                point_to_segment_distance(a2, b1, b2),
                point_to_segment_distance(b1, a1, a2),
                point_to_segment_distance(b2, a1, a2),
            ]
            min_dist = min(min_dist, *dists)
    
    return min_dist


def point_to_segment_distance(p, a, b):
    """Compute distance from point p to segment ab."""
    ap = p - a
    ab = b - a
    t = np.clip(np.dot(ap, ab) / np.dot(ab, ab), 0, 1)
    closest = a + t * ab
    return np.linalg.norm(p - closest)


@composable
def near_ego(
    track_uuid:Union[list,dict], 
    log_dir:Path,
    distance_thresh:float=50)->dict:
    """
    Returns timestamps where the object is near the ego vehicle
    """

    pos, timestamps = get_nth_pos_deriv(track_uuid, 0, log_dir, coordinate_frame=get_ego_uuid(log_dir))
    near_ego_timestamps = timestamps[np.linalg.norm(pos) < distance_thresh]

    return near_ego_timestamps


@cache_manager.create_cache('post_process_scenario')
def post_process_scenario(scenario, log_dir) -> dict:
    """
    1. Filter out referred objects that are only referred for 1 timestamp (likely noise)
    2. Filter out relationships (referred and related objects) with a relative distance of over 50m. 
    3. If a referred object is referred for less than 1.5s, expand the referred timestamps symmetrically in both directions to hit 1.5s.

    Return False if scenario was removed or filtered down to an empty set. Return true if there still exist referred objects with timestamps.
    """

    remove_empty_branches(scenario)
    if dict_empty(scenario):
        return True

    #remove_empty_branches(scenario)
    #filter_by_length(scenario, min_timesteps=2)
    filter_by_relationship_distance(scenario, log_dir, max_distance=50)
    dilate_timestamps(scenario, log_dir, min_timespan_s=1.5)

    if dict_empty(scenario):
        return False
    else:
        return True


def filter_by_length(scenario, min_timesteps=2):

    for track_uuid, related_objects in list(scenario.items()):
        if isinstance(related_objects, list) or isinstance(related_objects, set):
            if len(related_objects) < min_timesteps:
                scenario.pop(track_uuid)
        else:
            filter_by_length(related_objects, min_timesteps)


def filter_by_relationship_distance(scenario, log_dir, max_distance=50):
    
    for track_uuid, related_objects in list(scenario.items()):
        if isinstance(related_objects, dict):
            for related_uuid, related_grandchildren in list(related_objects.items()):

                if isinstance(related_grandchildren, dict):
                    filter_by_relationship_distance(related_objects, log_dir, max_distance)

                traj, timestamps = get_nth_pos_deriv(related_uuid, 0, log_dir, coordinate_frame=track_uuid)
                related_timestamps = get_scenario_timestamps(related_grandchildren)
                related_position = traj[np.isin(timestamps, related_timestamps)]
                related_distance = np.linalg.norm(related_position, axis=1)

                if not np.any(related_distance < max_distance):
                    scenario[track_uuid].pop(related_uuid)


def dilate_timestamps(scenario, log_dir, min_timespan_s:float=1.5, log_df = None):

    if log_df is None:
        log_df = read_feather(log_dir / 'sm_annotations.feather')

    timestamps = sorted(log_df['timestamp_ns'].unique())
    timestep_s = 1E-9*(timestamps[1]-timestamps[0])
    min_length = round(min_timespan_s/timestep_s)

    for track_uuid, related_objects in scenario.items():
        if isinstance(related_objects, dict):
            dilate_timestamps(related_objects, log_dir, min_timespan_s, log_df=log_df)

        elif isinstance(related_objects, list):
            referred_timestamps = sorted(related_objects)
            track_av2_timestamps =  np.array(sorted(log_df.loc[log_df['track_uuid'] == track_uuid, 'timestamp_ns'].unique()))

            referred_indices = np.isin(track_av2_timestamps, referred_timestamps)

            index = 0
            while index < len(track_av2_timestamps):
                #traverse the array from left to right
                #if a 1 is reached, the left pointer stops and the right keeps going until it hits a 0
                    #if the right reaches a 0, calculate the distance between left and right
                    #if this distance < 15, update the left and right pointer indices to 1

                if referred_indices[index] == 0:
                    index += 1
                else:
                    left = index - 1
                    right = index + 1

                    while right < len(referred_indices) and referred_indices[right] == 1:
                        right += 1

                    len_time_seg = (right-left) - 1
                    dilation_size = (min_length - len_time_seg)//2

                    for _ in range(dilation_size):
                        if left >= 0:
                            referred_indices[left] = 1
                            left -= 1
                        if right < len(referred_indices):
                            referred_indices[right] = 1
                            right += 1

                    index = right

            scenario[track_uuid] = list(track_av2_timestamps[referred_indices])


def filter_by_roi(scenario, log_dir):
    """
    Remove scenarios that never have a referred object in side the region of interest.
    Keep scenarios that ever have a referred object in the region of interest as-is.
    """

    filtered_scenario = in_region_of_interest(scenario, log_dir)

    if dict_empty(filtered_scenario):
        if not dict_empty(scenario):
            print('Scenario has referred objects, but none within the region of interest.')

        return filtered_scenario
    else:
        return scenario


def swap_keys_and_listed_values(dict:dict[float,list])->dict[float,list]:
    
    swapped_dict = {}
    for key, timestamp_list in dict.items():
        for timestamp in timestamp_list:
            if timestamp not in swapped_dict:
                swapped_dict[timestamp] = []
            swapped_dict[timestamp].append(key)

    return swapped_dict



def dict_empty(d:dict):
    if len(d) == 0:
        return True

    for  value in d.values():
        if isinstance(value, list) and len(value) > 0:
            return False

        if isinstance(value, dict) and not dict_empty(value):
            return False
        
    return True


@composable_relational
def at_stop_sign_(track_uuid, stop_sign_uuids, log_dir, forward_thresh=10) -> tuple[list, dict[str,list]]:
    RIGHT_THRESH = 7 #m

    stop_sign_timestamps = []
    stop_signs = {}
    
    track_lanes = get_scenario_lanes(track_uuid, log_dir)

    for stop_sign_id in stop_sign_uuids:
        pos, _ = get_nth_pos_deriv(track_uuid, 0, log_dir, coordinate_frame=stop_sign_id)
        yaws, timestamps = get_nth_yaw_deriv(track_uuid, 0, log_dir, coordinate_frame=stop_sign_id, in_degrees=True)
        for i in range(len(timestamps)):
            if (-1<pos[i,0]<forward_thresh and -RIGHT_THRESH<pos[i,1]<0 
            and track_lanes.get(timestamps[i],None) 
            and stop_sign_lane(stop_sign_id, log_dir) 
            and track_lanes[timestamps[i]].id == stop_sign_lane(stop_sign_id, log_dir).id
            and (yaws[i] >= 90 or yaws[i] <= -90)):

                if stop_sign_id not in stop_signs:
                    stop_signs[stop_sign_id] = []
                stop_signs[stop_sign_id].append(timestamps[i])
            
                if timestamps[i] not in stop_sign_timestamps:
                    stop_sign_timestamps.append(timestamps[i])

    return stop_sign_timestamps, stop_signs


@composable
def occluded(track_uuid, log_dir):

    annotations_df = read_feather(log_dir / 'sm_annotations.feather')
    track_df = annotations_df[annotations_df['track_uuid'] == track_uuid]
    track_when_occluded = track_df[track_df['num_interior_pts'] == 0]

    if track_when_occluded.empty:
        return []
    else:
        return sorted(track_when_occluded['timestamp_ns'])


def stop_sign_lane(stop_sign_id, log_dir) -> LaneSegment:
    avm = get_map(log_dir)
    pos, _ = get_nth_pos_deriv(stop_sign_id, 0, log_dir)

    ls_list = avm.get_nearby_lane_segments(pos[0,:2], 10)
    best_ls = None
    best_dist = np.inf
    for ls in ls_list:
        dist = np.linalg.norm(pos[0]-ls.right_lane_boundary.xyz[-1])

        if not ls.is_intersection and dist < best_dist:
            best_ls = ls

    if best_ls == None:
        for ls in ls_list:
            dist = np.linalg.norm(pos[0]-ls.right_lane_boundary.xyz[-1])

            if dist < best_dist:
                best_ls = ls
    
    return best_ls


def get_pos_within_lane(pos, ls: LaneSegment) -> tuple:

    if not ls or not is_point_in_polygon(pos[:2], ls.polygon_boundary[:,:2]):
        return None, None

    #Projecting to 2D for BEV
    pos = pos[:2]
    left_line = ls.left_lane_boundary.xyz[:,:2]
    right_line = ls.right_lane_boundary.xyz[:,:2]

    left_dist = 0
    left_point = None
    left_total_length = 0
    min_dist = np.inf
    for i in range(1, len(left_line)):
        segment_start = left_line[i-1]
        segment_end = left_line[i]

        segment_length = np.linalg.norm(segment_end-segment_start)
        segment_direction = (segment_end-segment_start)/segment_length
        segment_proj = np.dot((pos-segment_start), segment_direction)*segment_direction
        proj_length = np.linalg.norm(segment_proj)

        if 0 <= proj_length <= segment_length:
            proj_point = segment_start + segment_proj
        elif proj_length < 0:
            proj_point = segment_start
        else:
            proj_point = segment_end

        proj_dist = np.linalg.norm(pos-proj_point)

        if proj_dist < min_dist:
            min_dist = proj_dist
            left_point = segment_start + segment_proj
            left_dist = left_total_length + proj_length

        left_total_length += segment_length

    right_dist = 0
    right_point = None
    right_total_length = 0
    min_dist = np.inf
    for i in range(1, len(right_line)):
        segment_start = right_line[i-1]
        segment_end = right_line[i]

        segment_length = np.linalg.norm(segment_end-segment_start)
        segment_direction = (segment_end-segment_start)/segment_length
        segment_proj = np.dot((pos-segment_start), segment_direction)*segment_direction
        proj_length = np.linalg.norm(segment_proj)

        if 0 <= proj_length <= segment_length:
            proj_point = segment_start + segment_proj
        elif proj_length < 0:
            proj_point = segment_start
        else:
            proj_point = segment_end

        proj_dist = np.linalg.norm(pos-proj_point)

        if proj_dist < min_dist:
            min_dist = proj_dist
            right_point = segment_start + segment_proj
            right_dist = right_total_length + proj_length

        right_total_length += segment_length

    if left_point is not None and right_point is not None:
        total_length = (left_total_length + right_total_length)/2
        distance = (left_dist + right_dist)/2
        pos_along_length = distance/total_length

        total_width = np.linalg.norm(left_point - right_point)
        lateral_dir_vec = (left_point - right_point)/total_width
        lateral_proj = np.dot((pos-left_point), lateral_dir_vec)*lateral_dir_vec
        pos_along_width = np.linalg.norm(lateral_proj)/total_width
        return pos_along_length, pos_along_width
    
    else:
        print("Position not found within lane_segment. Debug function further.")
        return None, None


@composable
def in_region_of_interest(track_uuid, log_dir):

    in_roi_timestamps = []

    avm = get_map(log_dir)
    timestamps = get_timestamps(track_uuid, log_dir)
    ego_poses = get_ego_SE3(log_dir)

    for timestamp in timestamps:
        cuboid = get_cuboid_from_uuid(track_uuid, log_dir, timestamp=timestamp)
        ego_to_city = ego_poses[timestamp]
        city_cuboid = cuboid.transform(ego_to_city)
        city_vertices = city_cuboid.vertices_m
        city_vertices = city_vertices.reshape(-1, 3)[:,:2]
        is_within_roi = avm.get_raster_layer_points_boolean(city_vertices, layer_name="ROI")
        if is_within_roi.any():
            in_roi_timestamps.append(timestamp)

    return in_roi_timestamps


def remove_empty_branches(scenario_dict):
    
    if isinstance(scenario_dict, dict):
        track_uuids = list(scenario_dict.keys())
        for track_uuid in track_uuids:
            children = scenario_dict[track_uuid]
            timestamps = get_scenario_timestamps(children)
            if len(timestamps) == 0:
                scenario_dict.pop(track_uuid)
            else:
                remove_empty_branches(children)


def get_scenario_timestamps(scenario_dict:dict) -> list:
    if not isinstance(scenario_dict, dict):
        #Scenario dict is a list of timestamps
        return scenario_dict

    timestamps = []
    for relationship in scenario_dict.values():
        timestamps.extend(get_scenario_timestamps(relationship))

    return sorted(list(set(timestamps)))


def get_scenario_uuids(scenario_dict:dict) -> list:
    if get_scenario_timestamps(scenario_dict):
        scenario_uuids = list(scenario_dict.keys())
        for child in scenario_dict.items():
            if isinstance(child, dict):
                scenario_uuids.extend(get_scenario_uuids(child))
        return list(set(scenario_uuids))
    else:
        return []


def reconstruct_track_dict(scenario_dict):
    track_dict = {}

    for track_uuid, related_objects in scenario_dict.items():
        if isinstance(related_objects, dict):
            timestamps = get_scenario_timestamps(related_objects)
            if len(timestamps) > 0:
                track_dict[track_uuid] = get_scenario_timestamps(related_objects)
        else:
            if len(related_objects) > 0:
                track_dict[track_uuid] = related_objects

    return track_dict


def reconstruct_relationship_dict(scenario_dict):
    #Reconstructing legacy relationship dict

    relationship_dict = {track_uuid: {} for track_uuid in scenario_dict.keys()}

    for track_uuid, child in scenario_dict.items():
        if not isinstance(child, dict):
            continue
        
        descendants = get_objects_and_timestamps(scenario_dict[track_uuid])
        for related_uuid, timestamps in descendants.items():
            relationship_dict[track_uuid][related_uuid] = timestamps

    return relationship_dict


def get_objects_and_timestamps(scenario_dict: dict) -> dict:
    track_dict = {}

    for uuid, related_children in scenario_dict.items():

        if isinstance(related_children, dict):
            track_dict[uuid] = get_scenario_timestamps(related_children)
            temp_dict = get_objects_and_timestamps(related_children)

            for child_uuid, timestamps in temp_dict.items():
                if child_uuid not in track_dict:
                    track_dict[child_uuid] = timestamps
                else:
                    track_dict[child_uuid] = sorted(list(track_dict[child_uuid]) + list(timestamps))
        else:
            if uuid not in track_dict:
                track_dict[uuid] = related_children
            else:
                track_dict[uuid] = sorted(list(set(track_dict[uuid] + list(related_children))))

    return track_dict


def print_indented_dict(d:dict, indent=0):
    """
    Recursively prints a dictionary with indentation.

    Args:
        d (dict): The dictionary to print.
        indent (int): The current indentation level (number of spaces).
    """
    for key, value in d.items():
        print(" " * indent + str(key) + ":")
        if isinstance(value, dict):
            print_indented_dict(value, indent=indent + 4)
        else:
            print(" " * (indent + 4) + str(value))


def extract_pkl_log(filename, log_id, output_dir='output', is_gt=False):
    sequences = load(filename)
    extracted_sequence = {log_id: sequences[log_id]}

    if is_gt:
        save(extracted_sequence, output_dir / f'{log_id}_gt_annotations.pkl')
    else:
        save(extracted_sequence, output_dir / f'{log_id}_extracted.pkl')


def get_related_objects(relationship_dict):
    track_dict = reconstruct_track_dict(relationship_dict)

    all_related_objects = {}

    for track_uuid, related_objects in relationship_dict.items():
        for related_uuid, timestamps in related_objects.items():
            if timestamps and related_uuid not in track_dict and related_uuid not in all_related_objects:
                all_related_objects[related_uuid] = timestamps
            elif timestamps and related_uuid not in track_dict and related_uuid in all_related_objects:
                all_related_objects[related_uuid] = sorted(set(all_related_objects[related_uuid]).union(timestamps))
            elif timestamps and related_uuid in track_dict and related_uuid not in all_related_objects:
                non_track_timestamps = sorted(set(track_dict[related_uuid]).difference(timestamps))
                if non_track_timestamps:
                    all_related_objects[related_uuid] = non_track_timestamps
            elif timestamps and related_uuid in track_dict and related_uuid in all_related_objects:
                non_track_timestamps = set(track_dict[related_uuid]).difference(timestamps)
                if non_track_timestamps:
                    all_related_objects[related_uuid] = sorted(set(all_related_objects[related_uuid]).union(non_track_timestamps))

    return all_related_objects


def get_objects_of_prompt(log_dir, prompt):
    return to_scenario_dict(get_uuids_of_prompt(log_dir, prompt), log_dir)

def get_uuids_of_prompt(log_dir, prompt):
    df = read_feather(log_dir / 'sm_annotations.feather')

    if prompt == 'ANY':
        uuids = df['track_uuid'].unique()
    else:
        category_df = df[df['prompt'] == prompt]
        uuids = category_df['track_uuid'].unique()

    return uuids


def create_mining_pkl(description, scenario, log_dir:Path, output_dir:Path):
    """
    Generates both a pkl file for evaluation and annotations for the scenario mining challenge.
    """

    log_id = log_dir.name
    frames = []
    (output_dir / log_id).mkdir(exist_ok=True)
    
    annotations = read_feather(log_dir / 'sm_annotations.feather')
    log_timestamps = sorted(annotations['timestamp_ns'].unique())
    all_uuids = list(annotations['track_uuid'].unique())
    ego_poses = get_ego_SE3(log_dir)

    try:
        with open(paths.SM_DOWNLOAD_DIR / 'eval_timestamps.json', 'rb') as file:
            eval_timestamps_by_log_id = json.load(file)
        eval_timestamps = eval_timestamps_by_log_id[log_id]
    except:
        # This assumes that your input has predictions for all of the timestamps
        # This is valid assumption for the RefProg code, but not for the baselines
        MAX_NUM_EVAL_TIMESTAMPS = 50
        if len(log_timestamps) > MAX_NUM_EVAL_TIMESTAMPS:
            eval_timestamps = log_timestamps[::5]
        else:
            eval_timestamps = log_timestamps

    referred_objects = swap_keys_and_listed_values(reconstruct_track_dict(scenario))
    relationships = reconstruct_relationship_dict(scenario)
    related_objects = swap_keys_and_listed_values(get_related_objects(relationships))

    for timestamp in eval_timestamps:
        frame = {}
        timestamp_annotations = annotations[annotations['timestamp_ns'] == timestamp]

        timestamp_uuids = list(timestamp_annotations['track_uuid'].unique())
        ego_to_city = ego_poses[timestamp]

        frame['seq_id'] = (log_id, description)
        frame['timestamp_ns'] = timestamp
        frame['ego_translation_m'] = list(ego_to_city.translation)
        frame['description'] = description

        n = len(timestamp_uuids)
        frame['translation_m'] = np.zeros((n, 3))
        frame['size'] = np.zeros((n,3), dtype=np.float32)
        frame['yaw'] = np.zeros(n, dtype=np.float32)
        frame['label'] = np.zeros(n, dtype=np.int32)
        frame['name'] = np.zeros(n, dtype='<U31')
        frame['track_id'] = np.zeros(n, dtype=np.int32)
        frame['score'] = np.zeros(n, dtype=np.float32)

        for i, track_uuid in enumerate(timestamp_uuids):
            track_df = timestamp_annotations[timestamp_annotations['track_uuid'] == track_uuid]
            if track_df.empty:
                continue
            
            cuboid = CuboidList.from_dataframe(track_df)[0]
            translation_m = ego_to_city.transform_from(cuboid.xyz_center_m)
            size = np.array([cuboid.length_m, cuboid.width_m, cuboid.height_m], dtype=np.float32)
            yaw = Rotation.from_matrix(ego_to_city.compose(cuboid.dst_SE3_object).rotation).as_euler('zxy')[0]

            if timestamp in referred_objects and track_uuid in referred_objects[timestamp]:
                category = "REFERRED_OBJECT"                                                                                                                            
                label = 0
            elif timestamp in related_objects and track_uuid in related_objects[timestamp]:
                category = "RELATED_OBJECT"
                label = 1
            else:
                category = "OTHER_OBJECT"
                label = 2

            frame['translation_m'][i,:] = translation_m
            frame['size'][i,:] = size
            frame['yaw'][i] = yaw
            frame['label'][i] = label
            frame['name'][i] = category
            frame['track_id'][i] = all_uuids.index(track_uuid)

            # Assign a score of 1 to tracker predictions that do not have an associated confidence value
            try:
                frame['score'][i] = float(track_df['score'].iloc[0])
            except:
                frame['score'][i] = 1.0

        frames.append(frame)

    sequences = {(log_id, description): frames}
    save(sequences, output_dir / log_id / f'{description}_predictions.pkl')
    print(f'Scenario pkl file for {description}_{log_id[:8]} saved successfully.')

    return True


def fix_pred_pkl(prediction_pkl:Path, label_pkl:Path, output_filename:Path) -> None:
    """
    Aligns the sequences and timestamps between a prediction PKL file with the label PKL file. 
    Pads the prediction pkl with a default prediction for timestamps and log-prompt pairs that are in the annotations
    PKL but not the prediction PKL. Remove timestamps found within the prediction PKL that are not within the label PKL
    """

    with open(prediction_pkl, 'rb') as file:
        predictions:dict = pickle.load(file)

    with open(label_pkl, 'rb') as file:
        labels:dict = pickle.load(file)   

    #Remove sequences and timestamps from the predictions that are not in the labels 
    filtered_predictions = {}

    for seq_id, pred_frames in predictions.items():
        if seq_id not in labels:
            continue

        label_frames = labels[seq_id]
        label_timestamps = []
        for frame in label_frames:
            label_timestamps.append(frame['timestamp_ns'])

        filtered_frames = []
        for frame in pred_frames:
            if frame['timestamp_ns'] in label_timestamps:
                filtered_frames.append(frame)

        filtered_predictions[seq_id] = filtered_frames

    if not filtered_predictions:
        print('Supplied prediction pkl and label pkl have no overlap! Make sure you are supplying the correct combination' \
        'of predictions and labels.')
        return

    #Add default sequences and timestamps that are in the labels but not in the timestamps
    fixed_predictions = {}

    for seq_id, label_frames in labels.items():
        frame_infos_dict = {}
        for frame in label_frames:
            timestamp = frame['timestamp_ns']
            frame_infos_dict[timestamp] = {
                'timestamp_ns': timestamp,
                'seq_id': frame['seq_id'],
                'ego_translation_m': frame['ego_translation_m']
            }
            if 'description' in frame:
                frame_infos_dict[timestamp]['description'] = frame['description']


        if seq_id not in filtered_predictions:
            default_sequence = create_default_sequence(frame_infos_dict)
            fixed_predictions[seq_id] = default_sequence
            continue

        pred_frames = filtered_predictions[seq_id]
        pred_timestamps = []
        for frame in pred_frames:
            pred_timestamps.append(frame['timestamp_ns'])

        for frame in label_frames:
            timestamp = frame['timestamp_ns']
            if timestamp not in pred_timestamps:
                print(f'Timestamp {timestamp} appended')
                pred_frames.append(create_default_frame(frame_infos_dict[timestamp]))

        assert len(pred_frames) == len(label_frames)
        fixed_predictions[seq_id] = pred_frames
    assert len(fixed_predictions) == len(labels)

    with open(output_filename, 'wb') as file:
        pickle.dump(fixed_predictions, file)


def create_default_frame(frame_infos) -> dict:

    frame = {}
    frame['seq_id'] = frame_infos['seq_id']
    frame['timestamp_ns'] = frame_infos['timestamp_ns']
    frame['ego_translation_m'] = frame_infos['ego_translation_m']
    if 'description' in frame_infos:
        frame['description'] = frame_infos['description']

    frame['translation_m'] = np.zeros((1, 3))
    frame['translation_m'][0] = frame['ego_translation_m']
    frame['velocity_m_per_s'] = np.zeros((1,3), dtype=np.float32)
    frame['size'] = np.zeros((1,3), dtype=np.float32)
    frame['yaw'] = np.zeros(1, dtype=np.float32)
    frame['label'] = np.array([2], dtype=np.int32)
    frame['name'] = np.array(['OTHER_OBJECT'], dtype='<U31')
    frame['track_id'] = np.zeros(1, dtype=np.int32)
    frame['score'] = np.zeros(1, dtype=np.float32)

    return frame


def create_default_sequence(frame_infos_dict:dict) -> list:
    sequence = []
    for frame_infos in frame_infos_dict.values():
        sequence.append(create_default_frame(frame_infos))

    return sequence